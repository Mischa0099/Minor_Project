Flask==2.3.3
Flask-CORS==4.0.0
Flask-SQLAlchemy==3.0.5
Flask-JWT-Extended==4.5.3
python-dotenv==1.0.0
Werkzeug==2.3.7
requests==2.32.5

# Optional MongoDB support
pymongo==4.5.1

# Optional / ML stack (uncomment/install to enable model-backed chat)
transformers==4.57.0
# CPU-only torch wheel is recommended for local dev (installed from PyTorch CPU index)
# Example install command for CPU: pip install torch --extra-index-url https://download.pytorch.org/whl/cpu
# If you want to pin a wheel in requirements, use the correct cp version for your Python.
# Below we reference the generic torch package; installer will resolve appropriate wheel.
torch
accelerate==1.10.1
google-generativeai==0.8.5
numpy==2.3.3

# Stable AI API alternatives (recommended over Gemini):
openai==1.3.0  # OpenAI API - stable, reliable, most popular option

# Notes:
# - Installing the ML stack will download model weights (hundreds of MB). Use the lazy loaders to avoid blocking startup.
# - AI Provider Priority (automatically selects first available):
#   1. OpenAI (set OPENAI_API_KEY) - RECOMMENDED: Most stable option
#   2. Ollama (set OLLAMA_BASE_URL or defaults to http://localhost:11434) - Free, local, no API key needed
#   3. Gemini (set GOOGLE_API_KEY and USE_GENAI=1) - Less stable
#   4. Local transformers (set USE_LOCAL_MODEL=1) - Basic fallback
# - For OpenAI: Get API key from https://platform.openai.com/api-keys
# - For Ollama: Install from https://ollama.ai, then run: ollama pull llama2 (or mistral, etc.)
